# Zero Touch Automation Loop for Network with Cloud Native Infrastructure

This project aims to implement a zero touch automation loop for network management using cloud-native infrastructure.

## Files

- `agent.py`: Contains the implementation of the RL_Agent class responsible for the reinforcement learning agent. It includes functions for getting actions, training the agent, and interacting with the environment.
              The `Input` of the RL agent is the `MSE Array` generated by inference.py, and the `output` is the yaml file which include the `new action set` to the testbed

- `model.py`: Includes the definition of the `Linear_QNet` class, which represents the Q-network used by the agent for making `predictions`. It also includes the QTrainer class for training the Q-network.

- `inference.py`: Performs inference using the trained model and calculates the mean squared error (MSE) for intensity data.

- `lstm_objects.py`: Contains LSTM objects used in the project.

## RL_Agent Class (agent.py)

The `RL_Agent` class represents the reinforcement learning agent. It has the following attributes:

- `lt`: Loop time.
- `rn`: Randomness factor.
- `dr`: Discount rate.
- `epsilon`: Epsilon value for exploration-exploitation tradeoff.
- `memory`: Replay memory for storing experiences.
- `model`: Q-network model.
- `trainer`: Q-trainer for training the model.

The `RL_Agent` class has the following important methods:

- `get_action(state)`: Takes the current state as input and returns the action to be taken by the agent based on the exploration-exploitation tradeoff.

- `remember(state, action, reward, next_state)`: Stores the experience tuple consisting of the current state, action, reward, and next state in the replay memory.

- `train_long_memory()`: Performs a long memory training step by sampling a batch of experiences from the replay memory and training the Q-network using them.

- `train_short_memory(state, action, reward, next_state)`: Performs a short memory training step by training the Q-network on a single experience tuple.

- `loop(loop_t)`: The main loop function that runs the reinforcement learning agent for a specified number of iterations. It interacts with the environment, gets actions, trains the agent, and updates the model.

## Usage

1. Install the required dependencies by running:
   ```bash
   pip install numpy torch pyyaml
2. Update the parameters and implementation of the RL_Agent class in agent.py to fit your specific use case and environment.
3. Run the agent.py script:
    ```bash
    python agent.py
The script will run the reinforcement learning agent in the specified environment for the specified number of iterations.

## License
This project is licensed under the MIT License.